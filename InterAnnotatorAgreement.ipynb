{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyORhSqdUz00yYFHX1evP6ig"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Compute Inter-annotator agreement for manually annotated data"],"metadata":{"id":"9ovLEzIiAbfl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bKjUhX3jN8H2","collapsed":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import cohen_kappa_score, confusion_matrix, classification_report\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import matplotlib.font_manager as fm\n","\n","\n","\n","# === 1. Load the Annotation Files ===\n","def load_annotations(file_annotator1, file_annotator2):\n","    \"\"\"\n","    Loads two annotation files and merges them based on 'question_id_individual'.\n","    \"\"\"\n","    annotator1 = pd.read_csv(file_annotator1, delimiter=\";\")\n","    annotator2 = pd.read_csv(file_annotator2, delimiter=\";\")\n","\n","    # Rename columns to specify annotators\n","    annotator1 = annotator1.rename(columns={\n","        \"Conceptual Question Type\": \"Conceptual_A1\",\n","        \"Functional Question Type\": \"Functional_A1\"\n","    })\n","\n","    annotator2 = annotator2.rename(columns={\n","        \"Conceptual Question Type\": \"Conceptual_A2\",\n","        \"Functional Question Type\": \"Functional_A2\"\n","    })\n","\n","    # Merge on the unique question identifier\n","    merged_df = pd.merge(annotator1, annotator2, on=\"question_id_individual\", how=\"inner\")\n","\n","    print(f\"Data merged. {len(merged_df)} items matched between annotators.\")\n","\n","    return merged_df\n","\n","def compute_agreement(merged_df, column_A1, column_A2):\n","    \"\"\"\n","    Computes Cohen's Kappa and percentage agreement for a given annotation type.\n","    Handles missing values by dropping or replacing them.\n","    \"\"\"\n","    # Convert all labels to string to avoid type errors\n","    merged_df[column_A1] = merged_df[column_A1].astype(str)\n","    merged_df[column_A2] = merged_df[column_A2].astype(str)\n","\n","    # Drop rows where either annotation is missing\n","    valid_entries = merged_df.dropna(subset=[column_A1, column_A2])\n","\n","    # Calculate percentage agreement\n","    total = len(valid_entries)\n","    agreement = sum(valid_entries[column_A1] == valid_entries[column_A2])\n","    percentage_agreement = agreement / total * 100 if total > 0 else 0\n","\n","    # Calculate Cohen’s Kappa\n","    kappa = cohen_kappa_score(valid_entries[column_A1], valid_entries[column_A2])\n","\n","    print(f\"\\n **{column_A1} vs {column_A2}**\")\n","    print(f\"Percentage Agreement: {percentage_agreement:.2f}%\")\n","    print(f\"Cohen’s Kappa: {kappa:.3f}\")\n","\n","    return percentage_agreement, kappa\n","\n","# === 3. Generate a Confusion Matrix ===\n","def plot_confusion_matrix(merged_df, column_A1, column_A2, title, filename):\n","    \"\"\"\n","    Plots a confusion matrix while ensuring that each individual cell has a fixed size.\n","    Saves the plot as a PDF file.\n","    \"\"\"\n","    import matplotlib.pyplot as plt\n","    import seaborn as sns\n","    from sklearn.metrics import confusion_matrix\n","\n","    # Convert labels to string type (avoid float issues)\n","    merged_df[column_A1] = merged_df[column_A1].astype(str)\n","    merged_df[column_A2] = merged_df[column_A2].astype(str)\n","\n","    # Drop NaN values\n","    merged_df = merged_df.dropna(subset=[column_A1, column_A2])\n","\n","    # Get all labels and compute the confusion matrix\n","    all_labels = sorted(set(merged_df[column_A1].unique()).union(set(merged_df[column_A2].unique())))\n","    cm = confusion_matrix(merged_df[column_A1], merged_df[column_A2], labels=all_labels)\n","\n","    # Specify the font file path and set the font family globally\n","    font_path = 'lmroman10-regular.otf'\n","    fm.fontManager.addfont(font_path)\n","    plt.rcParams['font.family'] = 'Latin Modern Roman'\n","\n","    # --- Compute figure size based on desired cell dimensions ---\n","    # Desired dimensions per cell in inches\n","    cell_width = 0.8\n","    cell_height = 0.8\n","    # Additional space for margins, labels, etc.\n","    margin_width = 2\n","    margin_height = 2\n","    num_labels = len(all_labels)\n","    fig_width = cell_width * num_labels + margin_width\n","    fig_height = cell_height * num_labels + margin_height\n","\n","    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n","    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n","                annot_kws={'fontsize': 16},\n","                xticklabels=all_labels, yticklabels=all_labels,\n","                square=True, linewidths=0.5, ax=ax)\n","    plt.xlabel(f\"Annotator 2\", fontsize=20, labelpad=20)\n","    plt.ylabel(f\"Annotator 1\", fontsize=20, labelpad=20)\n","    plt.xticks(rotation=45, ha=\"right\", fontsize=16)\n","    plt.yticks(rotation=0, fontsize=16)\n","\n","    # Adjust the colorbar (legend) font size:\n","    cbar = ax.collections[0].colorbar\n","    cbar.ax.tick_params(labelsize=16)\n","\n","    # Save the figure as a PDF file with the given filename\n","    fig.savefig(filename, format=\"pdf\", bbox_inches=\"tight\")\n","    plt.show()\n","\n","\n","# === 4. Run Full Analysis ===\n","def analyze_inter_annotator_agreement(file_annotator1, file_annotator2):\n","    \"\"\"\n","    Full pipeline: loads data, computes agreement, and visualizes disagreements.\n","    \"\"\"\n","    # Step 1: Load and merge annotation files\n","    merged_df = load_annotations(file_annotator1, file_annotator2)\n","\n","    # Step 2: Compute agreement metrics\n","    print(\"\\n**Agreement Results**\")\n","    conceptual_agreement = compute_agreement(merged_df, \"Conceptual_A1\", \"Conceptual_A2\")\n","    functional_agreement = compute_agreement(merged_df, \"Functional_A1\", \"Functional_A2\")\n","\n","    # Step 3: Plot confusion matrices\n","    print(\"\\n**Visualizing Disagreements**\")\n","    plot_confusion_matrix(merged_df, \"Conceptual_A1\", \"Conceptual_A2\", \"Conceptual Question Type\", \"confusion_matrix_conceptual.pdf\")\n","    plot_confusion_matrix(merged_df, \"Functional_A1\", \"Functional_A2\", \"Functional Question Type\", \"confusion_matrix_functional.pdf\")\n","\n","    return merged_df, conceptual_agreement, functional_agreement\n","\n","\n","# === 5. Example Usage ===\n","# File paths\n","file_annotator1 = \"extracted_questions_for_IAA_annotator1_after.csv\"\n","file_annotator2 = \"extracted_questions_for_IAA_annotator2_after.csv\"\n","\n","merged_data, conceptual_results, functional_results = analyze_inter_annotator_agreement(file_annotator1, file_annotator2)"]},{"cell_type":"markdown","source":["---\n","* Extract misaligned cases to get better understanding of tagging behaviour\n","\n","---"],"metadata":{"id":"Y2G5AyPQvliZ"}},{"cell_type":"code","source":["# Set pandas options to display entire width of output\n","pd.set_option('display.width', None)\n","pd.set_option('display.max_colwidth', None)\n","\n","def find_misalignments(merged_df, column_A1, column_A2, label_A1, label_A2):\n","    \"\"\"\n","    Find all instances where Annotator 1 assigned label_A1 but Annotator 2 assigned label_A2.\n","    \"\"\"\n","    mismatched_cases = merged_df[\n","        (merged_df[column_A1] == label_A1) & (merged_df[column_A2] == label_A2)\n","    ][[\"question_id_individual\", \"question_individual\", column_A1, column_A2]]\n","\n","    print(f\"\\n Cases where A1 labeled '{label_A1}' but A2 labeled '{label_A2}':\")\n","\n","    if mismatched_cases.empty:\n","        print(\"No such mismatches found\")\n","    else:\n","        print(mismatched_cases)\n","\n","    return mismatched_cases\n","\n","# Example: Find cases where A1 labeled \"Empowerment\" but A2 labeled \"Advice\"\n","empowerment_vs_advice = find_misalignments(\n","    merged_data, \"Conceptual_A1\", \"Conceptual_A2\", \"Empowerment\", \"Advice\"\n",")\n","\n","# Reset pandas display options to default if necessary\n","pd.reset_option('display.width')\n","pd.reset_option('display.max_colwidth')"],"metadata":{"id":"AwSZR6yFvwGq"},"execution_count":null,"outputs":[]}]}