{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN77O7lMGSWUZqBLCAVWl02"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["---\n","* Load data\n","\n","---"],"metadata":{"id":"iqs2gfhQi5Ly"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LMbNjo7-ix2o"},"outputs":[],"source":["import json\n","\n","# Load the training data\n","with open(\"TRAINING_DATA.json\", \"r\") as f:\n","    training_data = json.load(f)\n","\n","# Print a sample of the data to verify structure\n","print(training_data[:1])"]},{"cell_type":"markdown","source":["---\n","\n","* Install relevant packages\n","\n","---"],"metadata":{"id":"uF1IdlV1gUOs"}},{"cell_type":"code","source":["# Install SpaCy\n","!pip install spacy\n","\n","# Download the German model\n","!python -m spacy download de_core_news_lg\n","\n","# Install lookups package (contains lemma_lookup table and other language resources)\n","!pip install spacy-lookups-data"],"metadata":{"id":"n3MOC15jgfm1","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","* Split data into training and development/validation data\n","\n","---"],"metadata":{"id":"ko5MncSih7mN"}},{"cell_type":"code","source":["import json\n","import random\n","\n","# Load the training data\n","with open(\"TRAINING_DATA.json\", \"r\") as f:\n","    training_data = json.load(f)\n","\n","# Shuffle the data for randomness\n","random.seed(42)  # Set seed for reproducibility\n","random.shuffle(training_data)\n","\n","# Split into training (80%) and dev (20%)\n","split_index = int(0.8 * len(training_data))\n","train_data = training_data[:split_index]\n","dev_data = training_data[split_index:]\n","\n","# Save the splits to separate files\n","with open(\"train_data.json\", \"w\") as f:\n","    json.dump(train_data, f, ensure_ascii=False, indent=4)\n","\n","with open(\"dev_data.json\", \"w\") as f:\n","    json.dump(dev_data, f, ensure_ascii=False, indent=4)\n","\n","print(f\"Data split completed: {len(train_data)} training samples, {len(dev_data)} dev samples\")\n"],"metadata":{"id":"DcDyO4GCh8GC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","* Convert training data into DocBin, so spaCy can process it\n","\n","---"],"metadata":{"id":"3e1RbZMuuF4M"}},{"cell_type":"code","source":["import spacy\n","from spacy.tokens import DocBin, MorphAnalysis\n","import json\n","\n","# Load your base model\n","nlp = spacy.load(\"de_core_news_lg\")\n","\n","# Create DocBin to store annotated docs\n","train_doc_bin = DocBin()\n","dev_doc_bin = DocBin()\n","\n","# Process each sentence in training data\n","for text, annotations in train_data:\n","    doc = nlp.make_doc(text)\n","    spans = annotations.get(\"tokens\", [])\n","\n","    for i, token_data in enumerate(spans):\n","        if i < len(doc):\n","            token = doc[i]\n","            token.lemma_ = token_data[\"lemma\"]\n","            token.pos_ = token_data[\"pos\"]\n","            token.tag_ = token_data.get(\"tag\", \"\")\n","\n","            # Validate and assign morph\n","            morph_value = token_data.get(\"morph\", \"\")\n","            if morph_value and isinstance(morph_value, str):  # Ensure morph is a valid string\n","                try:\n","                    token.morph = MorphAnalysis(nlp.vocab, nlp.vocab.morphology.add(morph_value))\n","                except Exception as e:\n","                    print(f\"Skipping invalid morph for token: {token.text} - Error: {e}\")\n","                    token.morph = MorphAnalysis(nlp.vocab)  # Assign empty MorphAnalysis for invalid morphs\n","            else:\n","                token.morph = MorphAnalysis(nlp.vocab)\n","\n","    train_doc_bin.add(doc)\n","\n","# Process each sentence in dev data\n","for text, annotations in dev_data:\n","    doc = nlp.make_doc(text)\n","    spans = annotations.get(\"tokens\", [])\n","\n","    for i, token_data in enumerate(spans):\n","        if i < len(doc):\n","            token = doc[i]\n","            token.lemma_ = token_data[\"lemma\"]\n","            token.pos_ = token_data[\"pos\"]\n","            token.tag_ = token_data.get(\"tag\", \"\")\n","\n","            # Validate and assign morph\n","            morph_value = token_data.get(\"morph\", \"\")\n","            if morph_value and isinstance(morph_value, str):  # Ensure morph is a valid string\n","                try:\n","                    token.morph = MorphAnalysis(nlp.vocab, nlp.vocab.morphology.add(morph_value))\n","                except Exception as e:\n","                    print(f\"Skipping invalid morph for token: {token.text} - Error: {e}\")\n","                    token.morph = MorphAnalysis(nlp.vocab)  # Assign empty MorphAnalysis for invalid morphs\n","            else:\n","                token.morph = MorphAnalysis(nlp.vocab)\n","\n","    dev_doc_bin.add(doc)\n","\n","# Save to disk\n","train_doc_bin.to_disk(\"training_data.spacy\")\n","print(\"Training data saved to 'training_data.spacy'\")\n","\n","dev_doc_bin.to_disk(\"dev_data.spacy\")\n","print(\"Development data saved to 'dev_data.spacy'\")"],"metadata":{"collapsed":true,"id":"UUnurV-UuNPo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","* Setup training configuration\n","\n","---"],"metadata":{"id":"HmQollivui13"}},{"cell_type":"code","source":["# Config file defines the pipeline components and training parameters\n","!python -m spacy init config config.cfg --lang de --pipeline tagger,lemmatizer,morphologizer"],"metadata":{"id":"zhCvhBMHujJZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","* Fine-tune model\n","\n","---"],"metadata":{"id":"KWMGyLQyujgF"}},{"cell_type":"code","source":["# Apply config file to training and dev data\n","!python -m spacy train config.cfg --paths.train training_data.spacy --paths.dev dev_data.spacy --output ./output\n","# takes 4-6min"],"metadata":{"id":"OmFA1K9uuj53"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","* Load and test new model\n","\n","---"],"metadata":{"id":"dAEbgc7bu_p6"}},{"cell_type":"code","source":["# Load fine-tuned model\n","fine_tuned_nlp = spacy.load(\"./output/model-last\")\n","\n","# Load original SpaCy model\n","original_nlp = spacy.load(\"de_core_news_lg\")\n","\n","# Test sentence\n","text = \"Hallöchen, hallo, hi und moin, meine Nachbarin hat behauptet, die Erde sei eine Scheibe. Ich würde gerne wissen, was passieren würde, wenn herauskäme, dass die Erde wirklich eine Scheibe ist. Ich meine, was wäre dann? Ändert sich dann alles? Darf ich dann mit meinem Leben weitermachen wie bisher? Oder muss ich mein Leben umstellen? LG und MFG\"\n","\n","# Process with both models\n","doc_fine_tuned = fine_tuned_nlp(text)\n","doc_original = original_nlp(text)\n","\n","# Print side-by-side comparison (FT: fine-tuned; OG: original)\n","print(f\"{'Token':<15}{'FT Lemma':<15}{'OG Lemma':<15}{'FT POS':<15}{'OG POS':<15}{'FT Tag':<15}{'OG Tag':<15}{'FT Morph':<15}{'OG Morph':<25}\")\n","print(\"=\" * 150)\n","\n","for token_fine, token_orig in zip(doc_fine_tuned, doc_original):\n","    print(f\"{token_fine.text:<15}{token_fine.lemma_:<15}{token_orig.lemma_:<15}{token_fine.pos_:<15}{token_orig.pos_:<15}{token_fine.tag_:<15}{token_orig.tag_:<15}{str(token_fine.morph):<15}{str(token_orig.morph):<25}\")"],"metadata":{"id":"peBO9TBu3Pk1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(nlp.pipe_names)\n","print(fine_tuned_nlp.pipe_names)"],"metadata":{"id":"q1CDTPoldqeg"},"execution_count":null,"outputs":[]}]}